{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iWEpYYzG--Qc"
      },
      "outputs": [],
      "source": [
        "!pip install pypdf --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4C7Jewx3wlwd"
      },
      "outputs": [],
      "source": [
        "from langchain.chains import ConversationalRetrievalChain\n",
        "from langchain.document_loaders import TextLoader, PyPDFLoader\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.vectorstores import Chroma\n",
        "import glob"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFoiLWdwCwgj"
      },
      "source": [
        "## Step-1 :Data Importing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dM1yvZvewheE"
      },
      "outputs": [],
      "source": [
        "#Example of ConversationalRetrievalChain\n",
        "\n",
        "#Document Loading\n",
        "!wget https://raw.githubusercontent.com/venkatareddykonasani/Datasets/master/CIBIL_Report/All_Cibil_Docs.zip\n",
        "#Unzip and Overwrite\n",
        "!unzip -o All_Cibil_Docs.zip -d All_Docs_Set1\n",
        "#listdown all documents content/All_Docs_Set1 and store them\n",
        "pdf_files = glob.glob(\"All_Docs_Set1/*.pdf\")\n",
        "print(pdf_files)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tIevEFt7-11C"
      },
      "outputs": [],
      "source": [
        "full_text = \"\"\n",
        "for pdf_file in pdf_files:\n",
        "    loader = PyPDFLoader(pdf_file)\n",
        "    pages = loader.load()\n",
        "    print(pdf_file, len(pages))\n",
        "    for page in pages:\n",
        "        full_text += page.page_content\n",
        "\n",
        "print(full_text[1:1000])\n",
        "print(\"Lines\" , len(full_text.split(\"\\n\")))\n",
        "print(\"Words\" , len(full_text.split(\" \")))\n",
        "print(\"Charecters\", len(full_text))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6nddR_wGDElT"
      },
      "source": [
        "## Step-2:Split the data into Chunks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t7vJzrSgC1Lb"
      },
      "outputs": [],
      "source": [
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=300, chunk_overlap=60)\n",
        "chunks = text_splitter.split_text(full_text)\n",
        "print(len(chunks))\n",
        "print(chunks[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ciwB4WJlFrr8"
      },
      "source": [
        "## Step-3: Creating embeddings and Storing in Vector Stores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YPb15teWG1Bk"
      },
      "outputs": [],
      "source": [
        "!pip install ChromaDB --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ssiV5nucAQol"
      },
      "outputs": [],
      "source": [
        "embeddings = OpenAIEmbeddings()\n",
        "cibil_db=Chroma.from_texts(chunks,\n",
        "                               embeddings,\n",
        "                               persist_directory=\"cibil_db\")\n",
        "cibil_db.persist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p_egFbt8UN4n"
      },
      "outputs": [],
      "source": [
        "retriever = cibil_db.as_retriever()\n",
        "result=retriever.get_relevant_documents(query=\"What is the CIBIL Score?\")\n",
        "for i in range(len(result)):\n",
        "  print(result[i].page_content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mk2tQsfsFyrs"
      },
      "source": [
        "## Step-4: Conversation and Retrieval Chain"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chat_models import ChatOpenAI, cohere\n",
        "from langchain.llms import Cohere"
      ],
      "metadata": {
        "id": "tqMgT-PxJLc2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kLrb6fpwFpk6"
      },
      "outputs": [],
      "source": [
        "llm= ChatOpenAI(temperature=0, max_tokens=512)\n",
        "#llm=Cohere(temperature=0, max_tokens=512)\n",
        "memory = ConversationBufferMemory(memory_key='chat_history', return_messages=True)\n",
        "conversational_RAG = ConversationalRetrievalChain.from_llm(llm=llm,\n",
        "                                                     retriever=cibil_db.as_retriever(),\n",
        "                                                     memory=memory,\n",
        "                                                     #verbose=True\n",
        "                                                     )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zr8Bc1ySIIQU"
      },
      "source": [
        "## Step-5 : Conversation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qqOdnx80FpoT"
      },
      "outputs": [],
      "source": [
        "user_input=input(\"Your message:\")\n",
        "while user_input!=\"quit\":\n",
        "    response=conversational_RAG({\"question\": user_input})\n",
        "    print(\"AI message ==>\", response[\"answer\"])\n",
        "    user_input=input(\"Your message: \")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RAG ChatBotTool"
      ],
      "metadata": {
        "id": "DSjFoQYdSCJo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile requirements.txt\n",
        "langchain\n",
        "langchain_community\n",
        "PyPDF2\n",
        "python-dotenv\n",
        "streamlit\n",
        "openai\n",
        "faiss-cpu\n",
        "altair\n",
        "tiktoken\n",
        "huggingface-hub\n",
        "InstructorEmbedding\n",
        "sentence-transformers\n",
        "pydantic"
      ],
      "metadata": {
        "id": "B0lEI8A0QjWO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt --quiet"
      ],
      "metadata": {
        "id": "pXiNMQMJTezd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "\n",
        "import streamlit as st\n",
        "from PyPDF2 import PdfReader\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.chains import ConversationalRetrievalChain\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "\n",
        "\n",
        "def get_pdf_text(pdf_docs):\n",
        "    text = \"\"\n",
        "    for pdf in pdf_docs:\n",
        "        pdf_reader = PdfReader(pdf)\n",
        "        for page in pdf_reader.pages:\n",
        "            text += page.extract_text()\n",
        "    return text\n",
        "\n",
        "def get_text_chunks(text):\n",
        "  text_splitter = CharacterTextSplitter(\n",
        "      separator=\"\\n\",\n",
        "      chunk_size=1000,\n",
        "      chunk_overlap=200,\n",
        "      length_function=len\n",
        "  )\n",
        "  chunks = text_splitter.split_text(text)\n",
        "  return chunks\n",
        "\n",
        "def get_embeddings(text_chunks):\n",
        "  embeddings = OpenAIEmbeddings()\n",
        "  return embeddings\n",
        "\n",
        "def get_convesrational_chain(vectorstore):\n",
        "  llm = ChatOpenAI(temperature=0)\n",
        "  memory = ConversationBufferMemory(memory_key='chat_history', return_messages=True)\n",
        "  convesrational_chain = ConversationalRetrievalChain.from_llm(\n",
        "      llm=llm,\n",
        "      retriever=vectorstore.as_retriever(),\n",
        "      memory=memory\n",
        "  )\n",
        "  return convesrational_chain\n",
        "\n",
        "\n",
        "def handle_userinput(user_question):\n",
        "  response = st.session_state.convesrational_chain({\"question\": user_question})\n",
        "  st.session_state.chat_history = response['chat_history']\n",
        "\n",
        "  for i, message in enumerate(st.session_state.chat_history):\n",
        "    if i % 2 == 0 :\n",
        "      st.write(':man_in_tuxedo:', message.content)\n",
        "    else:\n",
        "      st.write(':robot_face:', message.content)\n",
        "\n",
        "def main():\n",
        "\n",
        "    st.set_page_config(page_title=\"Chat with Documents\", page_icon=\":books:\")\n",
        "    styl = f\"\"\"\n",
        "      <style>\n",
        "          .stTextInput {{\n",
        "            position: fixed;\n",
        "            bottom: 3rem;\n",
        "          }}\n",
        "      </style>\n",
        "      \"\"\"\n",
        "    st.markdown(styl, unsafe_allow_html=True)\n",
        "\n",
        "    #st.write(css, unsafe_allow_html=True)\n",
        "    st.title(\"AI Chat-Bot for Your Documents :books:\")\n",
        "\n",
        "    if \"convesrational_chain\" not in st.session_state:\n",
        "        st.session_state.convesrational_chain = None\n",
        "    if \"chat_history\" not in st.session_state:\n",
        "        st.session_state.chat_history = None\n",
        "\n",
        "\n",
        "    user_input=st.text_input(\"Upload files, Hit Submit button, then ask questions.:blue[- Pratik Gabhane]:sunglasses:\")\n",
        "    if user_input:\n",
        "      handle_userinput(user_input)\n",
        "\n",
        "\n",
        "    with st.sidebar:\n",
        "        pdf_docs=st.file_uploader(\"Upload your documents here\" , accept_multiple_files=True)\n",
        "        if st.button(\"Submit\"):\n",
        "          with st.spinner(\"Processing...\"):\n",
        "\n",
        "            # Get PDF Data\n",
        "            raw_text=get_pdf_text(pdf_docs)\n",
        "\n",
        "            #Divide the Data into Chunks\n",
        "            chunked_array=get_text_chunks(raw_text)\n",
        "\n",
        "            #Create embeddings\n",
        "            embeddings=get_embeddings(chunked_array)\n",
        "\n",
        "            #Create vectorstore\n",
        "            vectorstore=FAISS.from_texts(chunked_array,embeddings)\n",
        "\n",
        "            #crate a converstaion chain\n",
        "            st.session_state.convesrational_chain=get_convesrational_chain(vectorstore)\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "Lb0BtRnzTkc6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run app.py & npx localtunnel --port 8501 & curl ipv4.icanhazip.com\n",
        "#Doesn't work in Chrome sometimes - Due to CSS related issues; Try Forefox"
      ],
      "metadata": {
        "id": "YphGHyMITyNq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}